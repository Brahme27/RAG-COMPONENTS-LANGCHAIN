{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3df60e7",
   "metadata": {},
   "source": [
    "## ALL ABOUT OPEN_AI EMBEDDINGS\n",
    "This is not an open source model,we should pay for it to use(a minimal amount of $5~ 500INR),i suggest you to please checkout,because most of the comapanies are using these api's,since these models provides a very good accuracy,compare to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a7ea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3399abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "It takes the `OPENAI_API_KEY` from your `.env` file and stores \n",
    "it in the system's environment variables so other parts \n",
    "of your code or libraries can use it.\n",
    "'''\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29dffe",
   "metadata": {},
   "source": [
    "## Embedding Techniques\n",
    "\n",
    "converting text to numeric vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8412032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_openai.embeddings.base.OpenAIEmbeddings"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "embeddings\n",
    "type(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3868e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"i really love to work in this field,which is trending now a days\"\n",
    "\n",
    "output_vectors=embeddings.embed_query(text)\n",
    "\n",
    "#output_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e2003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dimensions\n",
    "## this is the default dimensionsion of the output vector from openai embeddings\n",
    "len(output_vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a0e6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can also set the manual dimensions of the embedding vector\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\",dimensions=1536)\n",
    "\n",
    "output_vecors_1536=embeddings.embed_query(text)\n",
    "\n",
    "len(output_vecors_1536) #1536"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf931b",
   "metadata": {},
   "source": [
    "Okay till now,we have seen how to use openAi embeddings and convert them into vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4064ca",
   "metadata": {},
   "source": [
    "# Lets see the complete flow from data ingestion to storing vectors in vector store DB\n",
    "\n",
    "step1: Data ingestion\n",
    "\n",
    "step2: Splitting into chuncks\n",
    "\n",
    "step3: Storing vectors in vector store Db(Chroma db)\n",
    "\n",
    "step4: searching the query in vector store db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146cf4d",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "Data ingestion is the process of collecting and processing data from various sources, such as databases, APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fac0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader(\"speech.txt\")\n",
    "\n",
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50365646",
   "metadata": {},
   "source": [
    "## Splitting the documents into chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "874d2633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "\n",
    "final_docs=text_splitter.split_documents(documents)\n",
    "\n",
    "len(final_docs) # 3 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758da6a",
   "metadata": {},
   "source": [
    "## Storing vectors in vector store db\n",
    "here i used chroma db which is open source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d84f5599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x1c4cb05c250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db=Chroma.from_documents(documents=final_docs,embedding=embeddings)\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfd492",
   "metadata": {},
   "source": [
    "## Querying from vector store db using similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "017ba6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'speech.txt'}, page_content='To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.')]\n"
     ]
    }
   ],
   "source": [
    "## Lets do search on the vector store by using the query\n",
    "\n",
    "query=\"To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her\"\n",
    "\n",
    "retrived_results=db.similarity_search(query,k=1)\n",
    "\n",
    "print(retrived_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
